{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# N-grams Extractor\n",
    "## Objective: \n",
    "- Extract n-grams (bi/tri-grams) from a given group of texts to provide meaningful context into the data observed. \n",
    "## Techniques: \n",
    "- N-grams extraction \n",
    "- Smoothing: Laplace, Kneser-Ney Discounting\n",
    "- Intrinsic evaluation: perplexity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6139a29ce6e5f0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A. Import data and libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc21c89ad4741a5a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T13:44:23.897699Z",
     "start_time": "2023-09-18T13:44:22.227494Z"
    }
   },
   "id": "de2dfb93d7a388af"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 61\u001B[0m\n\u001B[1;32m     59\u001B[0m \u001B[38;5;66;03m# Process any remaining files\u001B[39;00m\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch:\n\u001B[0;32m---> 61\u001B[0m     \u001B[43mprocess_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcurrent_filename\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[6], line 24\u001B[0m, in \u001B[0;36mprocess_batch\u001B[0;34m(file_list, current_filename)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m# Load the Excel file into a DataFrame\u001B[39;00m\n\u001B[1;32m     23\u001B[0m file_path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(folder_path, filename)\n\u001B[0;32m---> 24\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mopenpyxl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Extract sanitized_text column\u001B[39;00m\n\u001B[1;32m     27\u001B[0m sanitized_texts \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcleanedtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mdropna()\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_base.py:517\u001B[0m, in \u001B[0;36mread_excel\u001B[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001B[0m\n\u001B[1;32m    511\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    512\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEngine should not be specified when passing \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    513\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124man ExcelFile - ExcelFile already has the engine set\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    514\u001B[0m     )\n\u001B[1;32m    516\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 517\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mio\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    526\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfalse_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfalse_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    527\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    528\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    529\u001B[0m \u001B[43m        \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    530\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeep_default_na\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_default_na\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    531\u001B[0m \u001B[43m        \u001B[49m\u001B[43mna_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    532\u001B[0m \u001B[43m        \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    533\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    534\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_parser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    536\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthousands\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthousands\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    537\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecimal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecimal\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    538\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    539\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskipfooter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipfooter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    540\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    541\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    543\u001B[0m     \u001B[38;5;66;03m# make sure to close opened file handles\u001B[39;00m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_close:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_base.py:1629\u001B[0m, in \u001B[0;36mExcelFile.parse\u001B[0;34m(self, sheet_name, header, names, index_col, usecols, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, date_format, thousands, comment, skipfooter, dtype_backend, **kwds)\u001B[0m\n\u001B[1;32m   1589\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse\u001B[39m(\n\u001B[1;32m   1590\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   1591\u001B[0m     sheet_name: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1609\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds,\n\u001B[1;32m   1610\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, DataFrame] \u001B[38;5;241m|\u001B[39m \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mint\u001B[39m, DataFrame]:\n\u001B[1;32m   1611\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1612\u001B[0m \u001B[38;5;124;03m    Parse specified sheet(s) into a DataFrame.\u001B[39;00m\n\u001B[1;32m   1613\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1627\u001B[0m \u001B[38;5;124;03m    >>> file.parse()  # doctest: +SKIP\u001B[39;00m\n\u001B[1;32m   1628\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1629\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1630\u001B[0m \u001B[43m        \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1631\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1632\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1633\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex_col\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1634\u001B[0m \u001B[43m        \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1635\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1636\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrue_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrue_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1637\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfalse_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfalse_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1638\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskiprows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1639\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnrows\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1640\u001B[0m \u001B[43m        \u001B[49m\u001B[43mna_values\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mna_values\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1641\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparse_dates\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1642\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_parser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1643\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdate_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1644\u001B[0m \u001B[43m        \u001B[49m\u001B[43mthousands\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthousands\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1645\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1646\u001B[0m \u001B[43m        \u001B[49m\u001B[43mskipfooter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskipfooter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1647\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype_backend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype_backend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1648\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1649\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_base.py:793\u001B[0m, in \u001B[0;36mBaseExcelReader.parse\u001B[0;34m(self, sheet_name, header, names, index_col, usecols, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, dtype_backend, **kwds)\u001B[0m\n\u001B[1;32m    790\u001B[0m     sheet \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_sheet_by_index(asheetname)\n\u001B[1;32m    792\u001B[0m file_rows_needed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_calc_rows(header, index_col, skiprows, nrows)\n\u001B[0;32m--> 793\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_sheet_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43msheet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile_rows_needed\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(sheet, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclose\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    795\u001B[0m     \u001B[38;5;66;03m# pyxlsb opens two TemporaryFiles\u001B[39;00m\n\u001B[1;32m    796\u001B[0m     sheet\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/io/excel/_openpyxl.py:616\u001B[0m, in \u001B[0;36mOpenpyxlReader.get_sheet_data\u001B[0;34m(self, sheet, file_rows_needed)\u001B[0m\n\u001B[1;32m    614\u001B[0m data: \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mlist\u001B[39m[Scalar]] \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    615\u001B[0m last_row_with_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[0;32m--> 616\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m row_number, row \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sheet\u001B[38;5;241m.\u001B[39mrows):\n\u001B[1;32m    617\u001B[0m     converted_row \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_convert_cell(cell) \u001B[38;5;28;01mfor\u001B[39;00m cell \u001B[38;5;129;01min\u001B[39;00m row]\n\u001B[1;32m    618\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m converted_row \u001B[38;5;129;01mand\u001B[39;00m converted_row[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    619\u001B[0m         \u001B[38;5;66;03m# trim trailing empty elements\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/worksheet/_read_only.py:81\u001B[0m, in \u001B[0;36mReadOnlyWorksheet._cells_by_row\u001B[0;34m(self, min_col, min_row, max_col, max_row, values_only)\u001B[0m\n\u001B[1;32m     77\u001B[0m src \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_source()\n\u001B[1;32m     78\u001B[0m parser \u001B[38;5;241m=\u001B[39m WorkSheetParser(src, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shared_strings,\n\u001B[1;32m     79\u001B[0m                          data_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mdata_only, epoch\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39mepoch,\n\u001B[1;32m     80\u001B[0m                          date_formats\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39m_date_formats)\n\u001B[0;32m---> 81\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m idx, row \u001B[38;5;129;01min\u001B[39;00m parser\u001B[38;5;241m.\u001B[39mparse():\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m max_row \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m idx \u001B[38;5;241m>\u001B[39m max_row:\n\u001B[1;32m     83\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/openpyxl/worksheet/_reader.py:156\u001B[0m, in \u001B[0;36mWorkSheetParser.parse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    137\u001B[0m properties \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    138\u001B[0m     PRINT_TAG: (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprint_options\u001B[39m\u001B[38;5;124m'\u001B[39m, PrintOptions),\n\u001B[1;32m    139\u001B[0m     MARGINS_TAG: (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpage_margins\u001B[39m\u001B[38;5;124m'\u001B[39m, PageMargins),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    151\u001B[0m \n\u001B[1;32m    152\u001B[0m }\n\u001B[1;32m    154\u001B[0m it \u001B[38;5;241m=\u001B[39m iterparse(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msource) \u001B[38;5;66;03m# add a finaliser to close the source when this becomes possible\u001B[39;00m\n\u001B[0;32m--> 156\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _, element \u001B[38;5;129;01min\u001B[39;00m it:\n\u001B[1;32m    157\u001B[0m     tag_name \u001B[38;5;241m=\u001B[39m element\u001B[38;5;241m.\u001B[39mtag\n\u001B[1;32m    158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tag_name \u001B[38;5;129;01min\u001B[39;00m dispatcher:\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/xml/etree/ElementTree.py:1254\u001B[0m, in \u001B[0;36miterparse.<locals>.iterator\u001B[0;34m(source)\u001B[0m\n\u001B[1;32m   1252\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m   1253\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m-> 1254\u001B[0m     \u001B[43mpullparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1255\u001B[0m root \u001B[38;5;241m=\u001B[39m pullparser\u001B[38;5;241m.\u001B[39m_close_and_return_root()\n\u001B[1;32m   1256\u001B[0m \u001B[38;5;28;01myield from\u001B[39;00m pullparser\u001B[38;5;241m.\u001B[39mread_events()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/xml/etree/ElementTree.py:1292\u001B[0m, in \u001B[0;36mXMLPullParser.feed\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1292\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_parser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfeed\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1293\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mSyntaxError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m   1294\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_events_queue\u001B[38;5;241m.\u001B[39mappend(exc)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/xml/etree/ElementTree.py:1709\u001B[0m, in \u001B[0;36mXMLParser.feed\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1707\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Feed encoded data to parser.\"\"\"\u001B[39;00m\n\u001B[1;32m   1708\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1709\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mParse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m   1710\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error \u001B[38;5;28;01mas\u001B[39;00m v:\n\u001B[1;32m   1711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raiseerror(v)\n",
      "File \u001B[0;32m/Users/sysadmin/build/v3.11.5/Modules/pyexpat.c:416\u001B[0m, in \u001B[0;36mStartElement\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/xml/etree/ElementTree.py:1647\u001B[0m, in \u001B[0;36mXMLParser._start\u001B[0;34m(self, tag, attr_list)\u001B[0m\n\u001B[1;32m   1645\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mlen\u001B[39m(attr_list), \u001B[38;5;241m2\u001B[39m):\n\u001B[1;32m   1646\u001B[0m         attrib[fixname(attr_list[i])] \u001B[38;5;241m=\u001B[39m attr_list[i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m-> 1647\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget\u001B[38;5;241m.\u001B[39mstart(tag, attrib)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = \"/Volumes/Samsung USB/spfcase_tm/output\"\n",
    "output_folder = \"/Volumes/Samsung USB/spfcase_tm/output\"\n",
    "batch_size = 100  # Adjust this based on your system's memory\n",
    "\n",
    "current_filename = None\n",
    "cleaned_text_list = []\n",
    "\n",
    "def process_batch(file_list, current_filename):\n",
    "    txt_files = []\n",
    "    \n",
    "    for filename in file_list:\n",
    "        if filename.endswith(\".xlsx\"):\n",
    "            # Check if the filename has changed\n",
    "            if current_filename != filename:\n",
    "                # Clear the cleaned_text_list when the filename changes\n",
    "                cleaned_text_list.clear()\n",
    "                current_filename = filename\n",
    "\n",
    "            # Load the Excel file into a DataFrame\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "            # Extract sanitized_text column\n",
    "            sanitized_texts = df['cleanedtext'].dropna().astype(str).tolist()\n",
    "\n",
    "            # Append to cleaned_text_list\n",
    "            cleaned_text_list.extend(sanitized_texts)\n",
    "\n",
    "            # Export the list as a txt file delimited by <s>, with the same file name\n",
    "            txt_filename = filename.replace(\".xlsx\", \".txt\")\n",
    "            txt_filepath = os.path.join(output_folder, txt_filename)\n",
    "            txt_files.append(txt_filepath)\n",
    "\n",
    "    # Batch file export\n",
    "    with open(txt_files, 'w') as txt_file:\n",
    "        txt_file.write(\"<s>\".join(cleaned_text_list))\n",
    "\n",
    "    # Batch file renaming\n",
    "    new_output_folder = os.path.join(output_folder, \"ngram-files\")\n",
    "    if not os.path.exists(new_output_folder):\n",
    "        os.makedirs(new_output_folder)\n",
    "\n",
    "    for txt_filepath in txt_files:\n",
    "        new_txt_filepath = os.path.join(new_output_folder, os.path.basename(txt_filepath))\n",
    "        os.rename(txt_filepath, new_txt_filepath)\n",
    "\n",
    "file_list = os.listdir(folder_path)\n",
    "batch = []\n",
    "\n",
    "for filename in file_list:\n",
    "    batch.append(filename)\n",
    "    if len(batch) >= batch_size:\n",
    "        process_batch(batch, current_filename)\n",
    "        batch.clear()\n",
    "\n",
    "# Process any remaining files\n",
    "if batch:\n",
    "    process_batch(batch, current_filename)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T15:11:11.647570Z",
     "start_time": "2023-09-18T15:10:29.909052Z"
    }
   },
   "id": "f2dbb38b3e26378e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# N. Kneser-Ney Discounting \n",
    "Describes the augmentation of absolute discounting with handling of lower-order unigram distributions. \n",
    "KN-D bases the estimate of P(Continuation) on the number of contexts that word _w_ appears in. \n",
    "We can express the number of times _w_ appears in some novel continuation as: \n",
    "$$P_{CONTINUATION}(w) \\propto \\: \\mid\\{v : \\: C(vw) > 0\\} \\mid$$\n",
    "\n",
    "Implementation for our probabilistic model: \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b723586d0f53ff2c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class KneserNeyLM:\n",
    "\n",
    "    def __init__(self, highest_order, ngrams, start_pad_symbol='<s>',\n",
    "            end_pad_symbol='</s>'):\n",
    "        \"\"\"\n",
    "        Constructor for KneserNeyLM.\n",
    "\n",
    "        Params:\n",
    "            highest_order [int] The order of the language model.\n",
    "            ngrams [list->tuple->string] Ngrams of the highest_order specified.\n",
    "                Ngrams at beginning / end of sentences should be padded.\n",
    "            start_pad_symbol [string] The symbol used to pad the beginning of\n",
    "                sentences.\n",
    "            end_pad_symbol [string] The symbol used to pad the beginning of\n",
    "                sentences.\n",
    "        \"\"\"\n",
    "        self.highest_order = highest_order\n",
    "        self.start_pad_symbol = start_pad_symbol\n",
    "        self.end_pad_symbol = end_pad_symbol\n",
    "        self.lm = self.train(ngrams)\n",
    "\n",
    "    def train(self, ngrams):\n",
    "        \"\"\"\n",
    "        Train the language model on the given ngrams.\n",
    "\n",
    "        Params:\n",
    "            ngrams [list->tuple->string] Ngrams of the highest_order specified.\n",
    "        \"\"\"\n",
    "        kgram_counts = self._calc_adj_counts(Counter(ngrams))\n",
    "        probs = self._calc_probs(kgram_counts)\n",
    "        return probs\n",
    "\n",
    "    def highest_order_probs(self):\n",
    "        return self.lm[0]\n",
    "\n",
    "    def _calc_adj_counts(self, highest_order_counts):\n",
    "        \"\"\"\n",
    "        Calculates the adjusted counts for all ngrams up to the highest order.\n",
    "\n",
    "        Params:\n",
    "            highest_order_counts [dict{tuple->string, int}] Counts of the highest\n",
    "                order ngrams.\n",
    "\n",
    "        Returns:\n",
    "            kgrams_counts [list->dict] List of dict from kgram to counts\n",
    "                where k is in descending order from highest_order to 0.\n",
    "        \"\"\"\n",
    "        kgrams_counts = [highest_order_counts]\n",
    "        for i in range(1, self.highest_order):\n",
    "            last_order = kgrams_counts[-1]\n",
    "            new_order = defaultdict(int)\n",
    "            for ngram in last_order.keys():\n",
    "                suffix = ngram[1:]\n",
    "                new_order[suffix] += 1\n",
    "            kgrams_counts.append(new_order)\n",
    "        return kgrams_counts\n",
    "\n",
    "    def _calc_probs(self, orders):\n",
    "        \"\"\"\n",
    "        Calculates interpolated probabilities of kgrams for all orders.\n",
    "        \"\"\"\n",
    "        backoffs = []\n",
    "        for order in orders[:-1]:\n",
    "            backoff = self._calc_order_backoff_probs(order)\n",
    "            backoffs.append(backoff)\n",
    "        orders[-1] = self._calc_unigram_probs(orders[-1])\n",
    "        backoffs.append(defaultdict(int))\n",
    "        self._interpolate(orders, backoffs)\n",
    "        return orders\n",
    "\n",
    "    def _calc_unigram_probs(self, unigrams):\n",
    "        sum_vals = sum(v for v in unigrams.values())\n",
    "        unigrams = dict((k, math.log(v/sum_vals)) for k, v in unigrams.items())\n",
    "        return unigrams\n",
    "\n",
    "    def _calc_order_backoff_probs(self, order):\n",
    "        num_kgrams_with_count = Counter(\n",
    "            value for value in order.values() if value <= 4)\n",
    "        discounts = self._calc_discounts(num_kgrams_with_count)\n",
    "        prefix_sums = defaultdict(int)\n",
    "        backoffs = defaultdict(int)\n",
    "        for key in order.keys():\n",
    "            prefix = key[:-1]\n",
    "            count = order[key]\n",
    "            prefix_sums[prefix] += count\n",
    "            discount = self._get_discount(discounts, count)\n",
    "            order[key] -= discount\n",
    "            backoffs[prefix] += discount\n",
    "        for key in order.keys():\n",
    "            prefix = key[:-1]\n",
    "            order[key] = math.log(order[key]/prefix_sums[prefix])\n",
    "        for prefix in backoffs.keys():\n",
    "            backoffs[prefix] = math.log(backoffs[prefix]/prefix_sums[prefix])\n",
    "        return backoffs\n",
    "\n",
    "    def _get_discount(self, discounts, count):\n",
    "        if count > 3:\n",
    "            return discounts[3]\n",
    "        return discounts[count]\n",
    "\n",
    "    def _calc_discounts(self, num_with_count):\n",
    "        \"\"\"\n",
    "        Calculate the optimal discount values for pgrams with counts 1, 2, & 3+.\n",
    "        \"\"\"\n",
    "        common = num_with_count[1]/(num_with_count[1] + 2 * num_with_count[2])\n",
    "        # Init discounts[0] to 0 so that discounts[i] is for counts of i\n",
    "        discounts = [0]\n",
    "        for i in range(1, 4):\n",
    "            if num_with_count[i] == 0:\n",
    "                discount = 0\n",
    "            else:\n",
    "                discount = (i - (i + 1) * common\n",
    "                        * num_with_count[i + 1] / num_with_count[i])\n",
    "            discounts.append(discount)\n",
    "        if any(d for d in discounts[1:] if d <= 0):\n",
    "            raise Exception(\n",
    "                '***Warning*** Non-positive discounts detected. '\n",
    "                'Your dataset is probably too small.')\n",
    "        return discounts\n",
    "\n",
    "    def _interpolate(self, orders, backoffs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for last_order, order, backoff in zip(\n",
    "                reversed(orders), reversed(orders[:-1]), reversed(backoffs[:-1])):\n",
    "            for kgram in order.keys():\n",
    "                prefix, suffix = kgram[:-1], kgram[1:]\n",
    "                order[kgram] += last_order[suffix] + backoff[prefix]\n",
    "\n",
    "    def logprob(self, ngram):\n",
    "        for i, order in enumerate(self.lm):\n",
    "            if ngram[i:] in order:\n",
    "                return order[ngram[i:]]\n",
    "        return None\n",
    "\n",
    "    def score_sent(self, sent):\n",
    "        \"\"\"\n",
    "        Return log prob of the sentence.\n",
    "\n",
    "        Params:\n",
    "            sent [tuple->string] The words in the unpadded sentence.\n",
    "        \"\"\"\n",
    "        padded = (\n",
    "            (self.start_pad_symbol,) * (self.highest_order - 1) + sent +\n",
    "            (self.end_pad_symbol,))\n",
    "        sent_logprob = 0\n",
    "        for i in range(len(sent) - self.highest_order + 1):\n",
    "            ngram = sent[i:i+self.highest_order]\n",
    "            sent_logprob += self.logprob(ngram)\n",
    "        return sent_logprob\n",
    "\n",
    "    def generate_sentence(self, min_length=4):\n",
    "        \"\"\"\n",
    "        Generate a sentence using the probabilities in the language model.\n",
    "\n",
    "        Params:\n",
    "            min_length [int] The mimimum number of words in the sentence.\n",
    "        \"\"\"\n",
    "        sent = []\n",
    "        probs = self.highest_order_probs()\n",
    "        while len(sent) < min_length + self.highest_order:\n",
    "            sent = [self.start_pad_symbol] * (self.highest_order - 1)\n",
    "            # Append first to avoid case where start & end symbal are same\n",
    "            sent.append(self._generate_next_word(sent, probs))\n",
    "            while sent[-1] != self.end_pad_symbol:\n",
    "                sent.append(self._generate_next_word(sent, probs))\n",
    "        sent = ' '.join(sent[(self.highest_order - 1):-1])\n",
    "        return sent\n",
    "\n",
    "    def _get_context(self, sentence):\n",
    "        \"\"\"\n",
    "        Extract context to predict next word from sentence.\n",
    "\n",
    "        Params:\n",
    "            sentence [tuple->string] The words currently in sentence.\n",
    "        \"\"\"\n",
    "        return sentence[(len(sentence) - self.highest_order + 1):]\n",
    "\n",
    "    def _generate_next_word(self, sent, probs):\n",
    "        context = tuple(self._get_context(sent))\n",
    "        pos_ngrams = list(\n",
    "            (ngram, logprob) for ngram, logprob in probs.items()\n",
    "            if ngram[:-1] == context)\n",
    "        # Normalize to get conditional probability.\n",
    "        # Subtract max logprob from all logprobs to avoid underflow.\n",
    "        _, max_logprob = max(pos_ngrams, key=lambda x: x[1])\n",
    "        pos_ngrams = list(\n",
    "            (ngram, math.exp(prob - max_logprob)) for ngram, prob in pos_ngrams)\n",
    "        total_prob = sum(prob for ngram, prob in pos_ngrams)\n",
    "        pos_ngrams = list(\n",
    "            (ngram, prob/total_prob) for ngram, prob in pos_ngrams)\n",
    "        rand = random.random()\n",
    "        for ngram, prob in pos_ngrams:\n",
    "            rand -= prob\n",
    "            if rand < 0:\n",
    "                return ngram[-1]\n",
    "        return ngram[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T08:17:17.117703Z",
     "start_time": "2023-09-18T08:17:17.098470Z"
    }
   },
   "id": "e7ce423b2ff2b45d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c67491a8a6db849b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "86896d85e79b5d1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
