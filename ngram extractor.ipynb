{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# N-grams Extractor\n",
    "## Objective: \n",
    "- Extract n-grams (bi/tri-grams) from a given group of texts to provide meaningful context into the data observed. \n",
    "## Techniques: \n",
    "- N-grams extraction \n",
    "- Smoothing: Laplace, Kneser-Ney Discounting\n",
    "- Intrinsic evaluation: perplexity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6139a29ce6e5f0a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A. Import data and libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc21c89ad4741a5a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import spacy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:00:07.666432600Z",
     "start_time": "2023-09-29T01:00:04.085422500Z"
    }
   },
   "id": "de2dfb93d7a388af"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = \"C:/Users/Clarence/Desktop/tm_220923/output\"\n",
    "# folder_path = \"/Users/clarence/Desktop/tm_ngramtest\"\n",
    "output_folder = \"C:/Users/Clarence/Desktop/tm_220923/output\"\n",
    "# output_folder = \"/Users/clarence/Desktop/tm_ngramtest\"\n",
    "\n",
    "current_filename = None\n",
    "cleaned_text_list = []\n",
    "    \n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):\n",
    "        # Check if the filename has changed\n",
    "        if current_filename != filename:\n",
    "            # Clear the cleaned_text_list when the filename changes\n",
    "            cleaned_text_list.clear()\n",
    "            current_filename = filename\n",
    "\n",
    "        # Load the Excel file into a DataFrame\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_excel(file_path)\n",
    "\n",
    "        # Extract sanitized_text column\n",
    "        sanitized_texts = df['cleanedtext'].dropna().astype(str).tolist()\n",
    "\n",
    "        # Append to cleaned_text_list\n",
    "        cleaned_text_list.extend([text for text in sanitized_texts])\n",
    "\n",
    "        # Export the list as a txt file delimited by <s>, with the same file name\n",
    "        txt_filename = filename.replace(\".xlsx\", \".txt\")\n",
    "        txt_filepath = os.path.join(output_folder, txt_filename)\n",
    "\n",
    "        with open(txt_filepath, 'w') as txt_file:\n",
    "            txt_file.write(\"\\n\".join(cleaned_text_list))\n",
    "\n",
    "new_output_folder = os.path.join(output_folder, \"ngram-files-290923\")\n",
    "if not os.path.exists(new_output_folder):\n",
    "    os.makedirs(new_output_folder)\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        txt_filepath = os.path.join(output_folder, filename)\n",
    "        new_txt_filepath = os.path.join(new_output_folder, filename)\n",
    "        os.rename(txt_filepath, new_txt_filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-29T01:02:36.512160400Z",
     "start_time": "2023-09-29T01:00:54.266405Z"
    }
   },
   "id": "f2dbb38b3e26378e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Text processing and preliminary N-gram construction\n",
    "\n",
    "With the extracted text files from each case classification, we clean up the punctuation marks and tokenise the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "518c4fbe720d76"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/Clarence/Desktop/tm_220923/output/ngram-files-290923\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aea42264f97b2ce8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# N. Kneser-Ney Discounting \n",
    "Describes the augmentation of absolute discounting with handling of lower-order unigram distributions. \n",
    "KN-D bases the estimate of P(Continuation) on the number of contexts that word _w_ appears in. \n",
    "We can express the number of times _w_ appears in some novel continuation as: \n",
    "$$P_{CONTINUATION}(w) \\propto \\: \\mid\\{v : \\: C(vw) > 0\\} \\mid$$\n",
    "\n",
    "Implementation for our probabilistic model: \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b723586d0f53ff2c"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "class KneserNeyLM:\n",
    "\n",
    "    def __init__(self, highest_order, ngrams, start_pad_symbol='<s>',\n",
    "            end_pad_symbol='</s>'):\n",
    "        \"\"\"\n",
    "        Constructor for KneserNeyLM.\n",
    "\n",
    "        Params:\n",
    "            highest_order [int] The order of the language model.\n",
    "            ngrams [list->tuple->string] Ngrams of the highest_order specified.\n",
    "                Ngrams at beginning / end of sentences should be padded.\n",
    "            start_pad_symbol [string] The symbol used to pad the beginning of\n",
    "                sentences.\n",
    "            end_pad_symbol [string] The symbol used to pad the beginning of\n",
    "                sentences.\n",
    "        \"\"\"\n",
    "        self.highest_order = highest_order\n",
    "        self.start_pad_symbol = start_pad_symbol\n",
    "        self.end_pad_symbol = end_pad_symbol\n",
    "        self.lm = self.train(ngrams)\n",
    "\n",
    "    def train(self, ngrams):\n",
    "        \"\"\"\n",
    "        Train the language model on the given ngrams.\n",
    "\n",
    "        Params:\n",
    "            ngrams [list->tuple->string] Ngrams of the highest_order specified.\n",
    "        \"\"\"\n",
    "        kgram_counts = self._calc_adj_counts(Counter(ngrams))\n",
    "        probs = self._calc_probs(kgram_counts)\n",
    "        return probs\n",
    "\n",
    "    def highest_order_probs(self):\n",
    "        return self.lm[0]\n",
    "\n",
    "    def _calc_adj_counts(self, highest_order_counts):\n",
    "        \"\"\"\n",
    "        Calculates the adjusted counts for all ngrams up to the highest order.\n",
    "\n",
    "        Params:\n",
    "            highest_order_counts [dict{tuple->string, int}] Counts of the highest\n",
    "                order ngrams.\n",
    "\n",
    "        Returns:\n",
    "            kgrams_counts [list->dict] List of dict from kgram to counts\n",
    "                where k is in descending order from highest_order to 0.\n",
    "        \"\"\"\n",
    "        kgrams_counts = [highest_order_counts]\n",
    "        for i in range(1, self.highest_order):\n",
    "            last_order = kgrams_counts[-1]\n",
    "            new_order = defaultdict(int)\n",
    "            for ngram in last_order.keys():\n",
    "                suffix = ngram[1:]\n",
    "                new_order[suffix] += 1\n",
    "            kgrams_counts.append(new_order)\n",
    "        return kgrams_counts\n",
    "\n",
    "    def _calc_probs(self, orders):\n",
    "        \"\"\"\n",
    "        Calculates interpolated probabilities of kgrams for all orders.\n",
    "        \"\"\"\n",
    "        backoffs = []\n",
    "        for order in orders[:-1]:\n",
    "            backoff = self._calc_order_backoff_probs(order)\n",
    "            backoffs.append(backoff)\n",
    "        orders[-1] = self._calc_unigram_probs(orders[-1])\n",
    "        backoffs.append(defaultdict(int))\n",
    "        self._interpolate(orders, backoffs)\n",
    "        return orders\n",
    "\n",
    "    def _calc_unigram_probs(self, unigrams):\n",
    "        sum_vals = sum(v for v in unigrams.values())\n",
    "        unigrams = dict((k, math.log(v/sum_vals)) for k, v in unigrams.items())\n",
    "        return unigrams\n",
    "\n",
    "    def _calc_order_backoff_probs(self, order):\n",
    "        num_kgrams_with_count = Counter(\n",
    "            value for value in order.values() if value <= 4)\n",
    "        discounts = self._calc_discounts(num_kgrams_with_count)\n",
    "        prefix_sums = defaultdict(int)\n",
    "        backoffs = defaultdict(int)\n",
    "        for key in order.keys():\n",
    "            prefix = key[:-1]\n",
    "            count = order[key]\n",
    "            prefix_sums[prefix] += count\n",
    "            discount = self._get_discount(discounts, count)\n",
    "            order[key] -= discount\n",
    "            backoffs[prefix] += discount\n",
    "        for key in order.keys():\n",
    "            prefix = key[:-1]\n",
    "            order[key] = math.log(order[key]/prefix_sums[prefix])\n",
    "        for prefix in backoffs.keys():\n",
    "            backoffs[prefix] = math.log(backoffs[prefix]/prefix_sums[prefix])\n",
    "        return backoffs\n",
    "\n",
    "    def _get_discount(self, discounts, count):\n",
    "        if count > 3:\n",
    "            return discounts[3]\n",
    "        return discounts[count]\n",
    "\n",
    "    def _calc_discounts(self, num_with_count):\n",
    "        \"\"\"\n",
    "        Calculate the optimal discount values for pgrams with counts 1, 2, & 3+.\n",
    "        \"\"\"\n",
    "        common = num_with_count[1]/(num_with_count[1] + 2 * num_with_count[2])\n",
    "        # Init discounts[0] to 0 so that discounts[i] is for counts of i\n",
    "        discounts = [0]\n",
    "        for i in range(1, 4):\n",
    "            if num_with_count[i] == 0:\n",
    "                discount = 0\n",
    "            else:\n",
    "                discount = (i - (i + 1) * common\n",
    "                        * num_with_count[i + 1] / num_with_count[i])\n",
    "            discounts.append(discount)\n",
    "        if any(d for d in discounts[1:] if d <= 0):\n",
    "            raise Exception(\n",
    "                '***Warning*** Non-positive discounts detected. '\n",
    "                'Your dataset is probably too small.')\n",
    "        return discounts\n",
    "\n",
    "    def _interpolate(self, orders, backoffs):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for last_order, order, backoff in zip(\n",
    "                reversed(orders), reversed(orders[:-1]), reversed(backoffs[:-1])):\n",
    "            for kgram in order.keys():\n",
    "                prefix, suffix = kgram[:-1], kgram[1:]\n",
    "                order[kgram] += last_order[suffix] + backoff[prefix]\n",
    "\n",
    "    def logprob(self, ngram):\n",
    "        for i, order in enumerate(self.lm):\n",
    "            if ngram[i:] in order:\n",
    "                return order[ngram[i:]]\n",
    "        return None\n",
    "\n",
    "    def score_sent(self, sent):\n",
    "        \"\"\"\n",
    "        Return log prob of the sentence.\n",
    "\n",
    "        Params:\n",
    "            sent [tuple->string] The words in the unpadded sentence.\n",
    "        \"\"\"\n",
    "        padded = (\n",
    "            (self.start_pad_symbol,) * (self.highest_order - 1) + sent +\n",
    "            (self.end_pad_symbol,))\n",
    "        sent_logprob = 0\n",
    "        for i in range(len(sent) - self.highest_order + 1):\n",
    "            ngram = sent[i:i+self.highest_order]\n",
    "            sent_logprob += self.logprob(ngram)\n",
    "        return sent_logprob\n",
    "\n",
    "    def generate_sentence(self, min_length=4):\n",
    "        \"\"\"\n",
    "        Generate a sentence using the probabilities in the language model.\n",
    "\n",
    "        Params:\n",
    "            min_length [int] The mimimum number of words in the sentence.\n",
    "        \"\"\"\n",
    "        sent = []\n",
    "        probs = self.highest_order_probs()\n",
    "        while len(sent) < min_length + self.highest_order:\n",
    "            sent = [self.start_pad_symbol] * (self.highest_order - 1)\n",
    "            # Append first to avoid case where start & end symbal are same\n",
    "            sent.append(self._generate_next_word(sent, probs))\n",
    "            while sent[-1] != self.end_pad_symbol:\n",
    "                sent.append(self._generate_next_word(sent, probs))\n",
    "        sent = ' '.join(sent[(self.highest_order - 1):-1])\n",
    "        return sent\n",
    "\n",
    "    def _get_context(self, sentence):\n",
    "        \"\"\"\n",
    "        Extract context to predict next word from sentence.\n",
    "\n",
    "        Params:\n",
    "            sentence [tuple->string] The words currently in sentence.\n",
    "        \"\"\"\n",
    "        return sentence[(len(sentence) - self.highest_order + 1):]\n",
    "\n",
    "    def _generate_next_word(self, sent, probs):\n",
    "        context = tuple(self._get_context(sent))\n",
    "        pos_ngrams = list(\n",
    "            (ngram, logprob) for ngram, logprob in probs.items()\n",
    "            if ngram[:-1] == context)\n",
    "        # Normalize to get conditional probability.\n",
    "        # Subtract max logprob from all logprobs to avoid underflow.\n",
    "        _, max_logprob = max(pos_ngrams, key=lambda x: x[1])\n",
    "        pos_ngrams = list(\n",
    "            (ngram, math.exp(prob - max_logprob)) for ngram, prob in pos_ngrams)\n",
    "        total_prob = sum(prob for ngram, prob in pos_ngrams)\n",
    "        pos_ngrams = list(\n",
    "            (ngram, prob/total_prob) for ngram, prob in pos_ngrams)\n",
    "        rand = random.random()\n",
    "        for ngram, prob in pos_ngrams:\n",
    "            rand -= prob\n",
    "            if rand < 0:\n",
    "                return ngram[-1]\n",
    "        return ngram[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-18T08:17:17.117703Z",
     "start_time": "2023-09-18T08:17:17.098470Z"
    }
   },
   "id": "e7ce423b2ff2b45d"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c67491a8a6db849b"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "86896d85e79b5d1f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
